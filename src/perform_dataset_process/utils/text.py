# video_1, audio_2, text_3, chunk_4
import os
import json
import logging
import configparser
from chonkie import SemanticChunker, SentenceChunker
from .embedding_model import SiliconFlowEmbeddings
from typing import List
from enum import Enum


logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)
class Language(Enum):
    EN = "en"
    ZH = "zh"
config = configparser.ConfigParser()
config.read('config.ini')

language_code = config.get('Settings', 'language', fallback='en')
LANGUAGE = Language.ZH if language_code == 'zh' else Language.EN

log.info(f"Using Language: {LANGUAGE}")

def extract_text_from_audio(audio_path):
    """
    Extracts text from an audio file.

    Args:
        audio_path (str): Path to the audio file.

    Returns:
        str: Extracted text.
    """
    basedir = os.path.dirname(audio_path)
    save_path = os.path.join(basedir, "text_3.json")
    
    # paraformer-zh is a multi-functional asr model
    # use vad, punc, spk or not as you need
    from funasr import AutoModel
    if LANGUAGE == Language.ZH:
        model = AutoModel(model="paraformer-zh", model_revision="v2.0.4",
                          vad_model="fsmn-vad", vad_model_revision="v2.0.4",
                          punc_model="ct-punc-c", punc_model_revision="v2.0.4",
                          # spk_model="cam++", spk_model_revision="v2.0.2",
                          )
        res = model.generate(input=audio_path, 
                         batch_size_s=300, 
                         hotword='魔搭')
    else:
        from modelscope.pipelines import pipeline
        from modelscope.utils.constant import Tasks
        # funasr ++model=iic/speech_paraformer_asr-en-16k-vocab4199-pytorch ++vad_model=fsmn-vad ++punc_model=ct-punc ++input=D:\xue\grd\Keyframe-Extraction-for-video-summarization\test\1.wav
        # funasr ++model=iic/speech_paraformer_asr-en-16k-vocab4199-pytorch ++vad_model=fsmn-vad ++punc_model=iic/punc_ct-transformer_cn-en-common-vocab471067-large ++input=D:\xue\grd\Keyframe-Extraction-for-video-summarization\test\1.wav ++output_dir=./test/2
        # iic/speech_paraformer_asr-en-16k-vocab4199-pytorch
        model = AutoModel(
            model="iic/speech_paraformer_asr-en-16k-vocab4199-pytorch",
            vad_model="fsmn-vad",
            punc_model="iic/punc_ct-transformer_cn-en-common-vocab471067-large",
        )
        # The `DecodingOptions` dictionary is used to specify various options for the speech decoding
        # process when generating text from an audio file. Here is a breakdown of the options:
        res = model.generate(
            input=audio_path,
        )
        text = res[0]['text']
        text_filtered = ''.join([char for char in text if char.isalnum() or char.isspace() or char.isalpha()])
        model_split = AutoModel(
            model='iic/speech_timestamp_prediction-v1-16k-offline'
        )
        ret = model_split.generate(input=(audio_path, text_filtered), data_type=('sound', 'text'))
        # TODO: rediculous errors here, the text generated by timestamp prediction is different from that from the ASR model
        res[0]['text_by_prediction'] = ret[0]['text']
        res[0]['timestamp'] = ret[0]['timestamp']
    
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(res[0], f, ensure_ascii=False, indent=4)
    return res[0]


def _extract_chunks_from_text(text, **kwargs):
    use_semantic_chunker = kwargs.get("use_semantic_chunker", False)
    if not use_semantic_chunker:
        log.info("Using sentence chunker.")
        print("Using sentence chunker.")
        if LANGUAGE == Language.EN:
            chunker = SentenceChunker(
                tokenizer_or_token_counter="gpt2",                # Supports string identifiers
                chunk_size=32,                                    # Maximum tokens per chunk
                chunk_overlap=0,                                 # Overlap between chunks
                min_sentences_per_chunk=1,                        # Minimum sentences in each chunk
                min_characters_per_sentence=12,                   # Minimum characters per sentence
                approximate=True,                                 # Use approximate token counting
                delim=[".", "?", "!", "\n"],                      # Delimiters to use for chunking
                include_delim="prev",                             # Include the delimiter in the chunk
                return_type="chunks"                              # Return Chunks or texts only 
            )
        else:
            chunker = SentenceChunker(
                tokenizer_or_token_counter="gpt2",                # Supports string identifiers
                chunk_size=64,                                    # Maximum tokens per chunk
                chunk_overlap=0,                                 # Overlap between chunks
                min_sentences_per_chunk=1,                        # Minimum sentences in each chunk
                min_characters_per_sentence=12,                   # Minimum characters per sentence
                approximate=True,                                 # Use approximate token counting
                delim=["\n", "。", "？", "！"],                    # Delimiters to use for chunking
                include_delim="prev",                             # Include the delimiter in the chunk
                return_type="chunks"                              # Return Chunks or texts only 
            )
        return chunker(text)
    else:
        log.info("Using semantic chunker.")
        print("Using semantic chunker.")
        chunker_semantic = SemanticChunker(
            embedding_model=SiliconFlowEmbeddings(),
            threshold=5,
            chunk_size=64,
            **kwargs
        )
        semantic_chunks = chunker_semantic(text)
        return semantic_chunks


def _kmp_search(pattern, text):
    """
    KMP algorithm for pattern matching.

    Args:
        pattern (str): The pattern to search for.
        text (str): The text to search within.

    Returns:
        list: List of start indices where the pattern is found in the text.
    """
    def compute_lps(pattern):
        lps = [0] * len(pattern)
        length = 0
        i = 1
        while i < len(pattern):
            if pattern[i] == pattern[length]:
                length += 1
                lps[i] = length
                i += 1
            else:
                if length != 0:
                    length = lps[length - 1]
                else:
                    lps[i] = 0
                    i += 1
        return lps

    lps = compute_lps(pattern)
    i = 0
    j = 0
    indices = []
    while i < len(text):
        if pattern[j] == text[i]:
            i += 1
            j += 1
        if j == len(pattern):
            indices.append(i - j)
            j = lps[j - 1]
        elif i < len(text) and pattern[j] != text[i]:
            if j != 0:
                j = lps[j - 1]
            else:
                i += 1
    return indices


def align_chunks_with_timestamps(text_path, **kwargs):
    """
    Aligns text chunks with their start and end timestamps.

    Args:
        text_path (str): Path to the text JSON file.
        use_semantic_chunker (bool): Whether to use semantic chunker or not.

    Returns:
        list: List of chunks with their start and end timestamps.
    """
    with open(text_path, "r", encoding="utf-8") as f:
        text_json = json.load(f)
    
    text = text_json["text"]
    if LANGUAGE == Language.EN:
        text_by_prediction = text_json["text_by_prediction"]
        meaningful_text = ''.join([char for char in text if char.isalnum() or char.isalpha() or char.isspace()])
        meaningful_text_by_prediction = ''.join([char for char in text_by_prediction if char.isalnum() or char.isalpha() or char.isspace()])
    else:
        meaningful_text = ''.join([char for char in text if char.isalnum() or '\u4e00' <= char <= '\u9fff' or char.isalpha()])
    timestamps = text_json["timestamp"]
    chunks = _extract_chunks_from_text(text, **kwargs)
    
    aligned_chunks = []
    current_char_index = 0

    start_tmp_for_each_word = []
    end_tmp_for_each_word = []
    if LANGUAGE == Language.ZH:
        character_list = meaningful_text
        assert len(character_list) == len(timestamps), "Length of text and timestamps do not match(Chinese)."
        start_tmp_for_each_word = [timestamps[idx][0] for idx in range(len(character_list))]
        end_tmp_for_each_word = [timestamps[idx][1] for idx in range(len(character_list))]
    else:
        word_list = list(filter(lambda x: not x.isspace() and not len(x) == 0, meaningful_text_by_prediction.split(' ')))
        assert len(word_list) == len(timestamps), "Length of text and timestamps do not match(English)."
        for idx, word in enumerate(word_list):
            start_tmp_for_each_word.extend([timestamps[idx][0]] * len(word))
            end_tmp_for_each_word.extend([timestamps[idx][1]] * len(word))
        meaningful_text = ''.join(word_list)
    timestamps = list(zip(start_tmp_for_each_word, end_tmp_for_each_word))
    
    for chunk in chunks:
        chunk_text = chunk.text
        meaningful_chunk_text = ''.join([char for char in chunk_text if char.isalnum() or '\u4e00' <= char <= '\u9fff' or char.isalpha()])
        start_indices = _kmp_search(meaningful_chunk_text.lower(), meaningful_text.lower())
        for start_index in start_indices:
            end_index = start_index + len(meaningful_chunk_text) - 1
            """
                timestamp is like [start_time, end_time], 
                using start_time as start_timestamp and end_time as end_timestamp of each chunk_timestamp
            """
            chunk_start_timestamp = timestamps[start_index][0]
            chunk_end_timestamp = timestamps[end_index][1]

            aligned_chunk = {
                "text": chunk_text.strip(),
                "start": round(chunk_start_timestamp / 1000, 2),
                "end": round(chunk_end_timestamp / 1000, 2)
            }
            aligned_chunks.append(aligned_chunk)
            current_char_index = end_index + 1

    assert current_char_index == len(timestamps), "Some characters are not aligned with any chunk."

    output_key = text_json['key']
    output = dict()
    output['key'] = output_key
    output['text'] = text
    output['chunks'] = aligned_chunks
    output_path = os.path.dirname(text_path) + "/chunk_4.json"
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=4)
    return aligned_chunks


if __name__ == "__main__":
    video_path = "./test/test/audio.wav"
    extract_text_from_audio(video_path)
    text_path = "./test/test/text_3.json"
    aligned_chunks = align_chunks_with_timestamps(text_path, use_semantic_chunker=False)
    for chunk in aligned_chunks:
        print(chunk)